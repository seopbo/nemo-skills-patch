# Judge prompt configuration for AudioBench evaluation
# Based on AudioBench's official production system with 0-5 rating scale


user: |-
  [Reference Answer]
  {expected_answer}

  [Model Answer]
  {generation}

  [Question]
  {question}

  [Task]
  Rate the model's answer based on its alignment with the reference answer, focusing on accuracy and relevance to the reference provided. Please be critical on the details. If the model response is something like 'cannot decide', please rate as 0.
  Criteria: Assess if the model's response mirrors the reference in terms of content, accuracy, and relevance.
  Score0: The answer is refusing to give concrete results, providing something like 'cannot decide'.
  Score0: The answer is completely misaligned, providing incorrect or irrelevant information compared to the reference.
  Score1: The answer shows minimal alignment, often misunderstanding or providing irrelevant details unrelated to the reference.
  Score2: The answer recognizes the topic but diverges significantly from the reference in accuracy or relevance.
  Score3: The answer aligns with the reference generally but lacks detail or precise accuracy in some aspects.
  Score4: The answer is mostly accurate and relevant, closely following the reference but could be clearer or more detailed.
  Score5: The answer is highly accurate, detailed, and matches the reference answer perfectly, capturing its essence and detail.

  Your response should be formatted as follows:
  Explanation: (Provide a concise explanation of your rating, comparing the reference answer with the model's response. "The reference answer is [XXX], while the model's answer is [YYY]. I think ...")
  Rating: (int)
