# Base pipeline (ground-truth available, no tool usage by default, boxed prompt).

cluster: slurm
suffix: ""  # Suffix for experiment names
dataset_name: "icho"  # Optional dataset name for id generation
base_output_dir: /workspace/DATA/_data/seed_data/${dataset_name}
expname: "${dataset_name}_prep"
mid_dir: "unfiltered"

# Input file for the first stage (generate_solutions)
# It must include the field "problem"
# All the data in this file will be processed with the same prompt
# Make sure the problems fit the prompt you are using
input_file: ""

# Can define initial dependency for the `generate_solutions` stage to run after
initial_dependency: None

num_random_seeds: 5

num_chunks: 5


# Define the full sequence of stages for this mode
pipeline_stages:
  - filter_problems             # Filter problems based on format
  - decontaminate               # Decontaminate problems
  - topics_labeling             # Label topics and subtopics
  - generate_solutions          # Generate solutions
  - difficulty_estimation       # Estimate difficulty of problems
  - aggregate                   # Aggregate all the metadata into a single file
  - filter_solutions            # Filter solutions
  - prepare_for_sft             # Prepare for SFT
  - convert_to_messages_format  # Convert to messages format for training
  - bucket                      # Bucket by token length

# Directory structure configuration
directories:
  step-0-filter-problems: ${base_output_dir}/solution-sdg/step-0-filter-problems
  step-1-decontaminate: ${base_output_dir}/solution-sdg/step-1-decontaminate
  step-2-topics-labeling: ${base_output_dir}/solution-sdg/step-2-topics-labeling
  step-3-difficulty-estimation: ${base_output_dir}/solution-sdg/step-3-difficulty-estimation
  step-4-generate-solutions: ${base_output_dir}/solution-sdg/step-4-generate-solutions
  step-5-aggregate: ${base_output_dir}/solution-sdg/step-5-aggregate
  step-6-filter-solutions: ${base_output_dir}/solution-sdg/step-6-filter-solutions
  step-7-prepare-for-sft: ${base_output_dir}/solution-sdg/step-7-prepare-for-sft
  step-8-convert-to-messages-format: ${base_output_dir}/solution-sdg/step-8-convert-to-messages-format
  step-9-bucket: ${base_output_dir}/solution-sdg/step-9-bucket

# Stage-specific configurations
stages:
  filter_problems:
    output_dir: ${directories.step-0-filter-problems}
    input_file: ${input_file}
    dataset_name: ${dataset_name}
    remove_expected_answer: ${stages.generate_solutions.make_majority_voting}
    expected_answer_field: "answer"
    remove_images: True
    num_options: null
    option_format_regex: null
    deduplicate: True
    dependencies:
      - initial_dependency

  decontaminate:
    output_dir: ${directories.step-1-decontaminate}
    input_file: ${directories.step-0-filter-problems}/final_result.jsonl
    test_sets:
      - ["hle", "text"]
      - ["mmlu", "test"]
      - ["mmlu-pro", "test"]
      - ["gpqa", "diamond"]
    model: /hf_models/Qwen2.5-32B-Instruct
    server_type: sglang
    server_gpus: 1
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 20
    dependencies:
      - filter_problems
  topics_labeling:
    output_dir: ${directories.step-2-topics-labeling}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl
    model: /hf_models/Qwen2.5-32B-Instruct
    server_type: sglang
    server_gpus: 8
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 5
    generation_keys:
      - topic
      - subtopic
    few_shots_name: stem_topics
    topic:
      - Mathematics
      - Chemistry
      - Physics
      - Biology
    subtopic:
      Chemistry:
        - Organic Chemistry
        - Inorganic Chemistry
        - General Chemistry
      Physics:
        - Quantum Mechanics
        - Classical Mechanics
        - General Physics
        - Relativistic Mechanics
        - Electromagnetism and Photonics
        - Optics and Acoustics
        - Condensed Matter Physics
        - High-energy Particle Physics
        - Astrophysics
      Biology:
        - Genetics
        - Molecular Biology
        - General Biology
    dependencies:
      - decontaminate

  difficulty_estimation:
    output_dir: ${directories.step-3-difficulty-estimation}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl  # Should have expected answers

    generation_kwargs:
      args:
        model: /hf_models/Qwen3-30B-A3B
        server_type: vllm
        server_gpus: 8
        server_nodes: 2
        dependent_jobs: 1
        num_random_seeds: 5
        num_chunks: 20
      ctx_args: >-
        ++prompt_config=generic/general-boxed
        ++inference.tokens_to_generate=16000

    judge_kwargs:
      args:
        model: /hf_models/Qwen2.5-32B-Instruct
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        num_random_seeds: ${stages.difficulty_estimation.generation_kwargs.args.num_random_seeds}
        dependent_jobs: 1
        num_chunks: 5
      ctx_args: >-
        ++prompt_config=judge/general-judge

    dependencies:
      - decontaminate

  generate_solutions:
    make_majority_voting: False
    output_dir: ${directories.step-4-generate-solutions}
    predicted_answer_regex: null
    predicted_answer_regex_field: null # if specified will use the field in the input file to extract the predicted answer regex
    make_judgement: True

    reasoning_effort: ++chat_template_kwargs.reasoning_effort=high
    prompt_config: ++prompt_config=generic/general-boxed
    code_tags: ""
    enable_code_execution: ""
    code_execution_limits: ""
    builtin_tools: ""

    generation_kwargs:
      args:
        input_file: ${directories.step-1-decontaminate}/final_result.jsonl
        model: /hf_models/gpt-oss-120b
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        dependent_jobs: 1
        num_chunks: ${num_chunks}
        num_random_seeds: ${num_random_seeds}
        server_args: "--async-scheduling"
        with_sandbox: False

      ctx_args: >-
        ${stages.generate_solutions.prompt_config}
        ${stages.generate_solutions.code_tags}
        ${stages.generate_solutions.enable_code_execution}
        ${stages.generate_solutions.code_execution_limits}
        ++max_concurrent_requests=1024
        ++inference.tokens_to_generate=16000
        ++inference.endpoint_type=text
        ++inference.temperature=1.0
        ++inference.top_p=1.0
        ${stages.generate_solutions.reasoning_effort}
        ${stages.generate_solutions.builtin_tools}

    judge_kwargs:
      ctx_args: >-
        ++prompt_config=judge/general-judge
      args:
        model: /hf_models/gpt-oss-20b
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        num_random_seeds: ${stages.generate_solutions.generation_kwargs.args.num_random_seeds}
        dependent_jobs: 1
        num_chunks: ${num_chunks}

    dependencies:
      - decontaminate

  aggregate:
    output_dir: ${directories.step-5-aggregate}
    solutions_path: ${directories.step-4-generate-solutions}/final_result.jsonl
    metadata_files:
      - ${directories.step-2-topics-labeling}/final_result.jsonl
      - ${directories.step-3-difficulty-estimation}/final_result.jsonl
    dependencies:
      - topics_labeling
      - difficulty_estimation
      - generate_solutions

  filter_solutions:
    output_dir: ${directories.step-6-filter-solutions}
    input_file: ${directories.step-5-aggregate}/final_result.jsonl
    only_correct_solutions: True
    generation_model_pass_rate_range: [-1.0, 1.0] # minimum exclusive, maximum inclusive
    difficulty_model_pass_rate_range: [-1.0, 1.0] # minimum exclusive, maximum inclusive
    only_samples_with_ground_truth_answer: True
    metadata_values:
      topic: ["Biology", "Chemistry", "Physics", "Mathematics", "Other", "undefined"]
    dependencies:
      - aggregate

  prepare_for_sft:
    output_dir: ${directories.step-7-prepare-for-sft}
    input_file: ${directories.step-6-filter-solutions}/final_result.jsonl
    prepare_data_kwargs:
      ctx_args: >-
        ${stages.generate_solutions.prompt_config}
        ${stages.generate_solutions.code_tags}
        ++tokenizer=/hf_models/gpt-oss-120b
        ++filters.drop_multi_boxed=false
        ++filters.remove_len_outlier_problems=false
        ++filters.remove_len_outlier_solutions=false
        ++filters.remove_no_think_tags=false
        ++filters.remove_contaminated=false
        ++filters.trim_solutions=false
        ${stages.generate_solutions.reasoning_effort}
        ${stages.generate_solutions.builtin_tools}
        ++assistant_end="'<|return|>'"
    dependencies:
      - filter_solutions

  convert_to_messages_format:
    output_dir: ${directories.step-8-convert-to-messages-format}
    input_file: ${directories.step-7-prepare-for-sft}/final_result.jsonl
    dependencies:
      - prepare_for_sft

  bucket:
    input_file: ${directories.step-7-prepare-for-sft}/final_result.jsonl
    output_dir: ${directories.step-9-bucket}
    tokenizer_path: /hf_models/Qwen2.5-32B-Instruct
    bucket_sizes:
      - 16000
      - 32000
      - 64000
    dependencies:
      - prepare_for_sft
