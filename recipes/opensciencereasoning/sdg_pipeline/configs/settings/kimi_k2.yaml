# Overrides the generation arguments with Kimi-K2-Thinking model parameters.

stages:
  generate_solutions:
    tokens_to_generate: ++inference.tokens_to_generate=200000
    endpoint_type: ++inference.endpoint_type=chat
    generation_kwargs:
      args:
        server_type: sglang
        server_gpus: 8
        server_nodes: 1
        server_args: '"--trust-remote-code --tool-call-parser kimi_k2 --reasoning-parser kimi_k2 --tp 8"'
        model: /hf_models/Kimi-K2-Thinking
