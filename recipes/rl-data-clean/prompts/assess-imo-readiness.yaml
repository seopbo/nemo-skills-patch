user: |-
  You are an IMO preparation expert and coach. Your task is to determine if this problem and its proof are suitable for training an AI model to solve IMO-level competition problems.

  Problem:
  {problem}

  Proof:
  {proof}

  Previous Quality Assessments:
  - Problem Quality: {problem_quality_summary}
  - Discussion Quality: {discussion_quality_summary}
  - Proof Quality: {proof_quality_summary}

  Evaluate IMO readiness across these dimensions:

  ## 1. OLYMPIAD_STYLE
  Is this a typical olympiad-style problem?
  - yes: Classic olympiad problem type (proof, construction, optimization)
  - borderline: Has olympiad elements but also computational/routine aspects
  - no: Not olympiad-style (pure computation, routine textbook exercise, or research-level)

  **Olympiad characteristics:**
  - Requires proof, not just calculation
  - Needs creativity and insight, not just applying formulas
  - Self-contained, doesn't require advanced theory
  - Has an "aha!" moment or key observation

  ## 2. PEDAGOGICAL_VALUE
  Would solving this problem help prepare someone for IMO?
  - high: Teaches important techniques, builds problem-solving skills
  - medium: Some learning value, reinforces standard methods
  - low: Limited learning value (too easy, too specific, or bad example)

  ## 3. DIFFICULTY_APPROPRIATENESS
  Is the difficulty appropriate for IMO training?
  - appropriate: IMO P1-P6 range (from accessible to very challenging)
  - too_easy: Trivial, below IMO level (routine textbook problem)
  - too_hard: Beyond competition level (research problem, open question, requires graduate-level knowledge)

  ## 4. PROOF_TEACHABILITY
  Can the proof technique be learned and generalized?
  - yes: Technique is generalizable, can be applied to similar problems
  - no: Solution is too specific, one-off trick, or relies on guessing

  ## 5. SUITABLE_FOR_RL_TRAINING
  Is this suitable for RL training?
  - yes: Clear problem + correct proof = good training signal
  - no: Ambiguous problem, incorrect/unclear proof, or unclear reward signal

  ## 6. IMO_READINESS_SCORE (0-100)
  Overall score indicating how suitable this is for IMO training.

  **Scoring guidelines:**
  - 90-100: Perfect IMO training data (outstanding quality across all dimensions)
  - 80-89: Excellent IMO training data (strong in all key areas)
  - 70-79: Good IMO training data (solid but with minor issues)
  - 60-69: Acceptable but not ideal (borderline quality)
  - 50-59: Marginal (significant issues, consider rejecting)
  - 0-49: Not suitable (reject)

  **Score calculation considerations:**
  - Olympiad style (weight: 25%)
  - Pedagogical value (weight: 20%)
  - Difficulty appropriateness (weight: 20%)
  - Proof teachability (weight: 20%)
  - Previous quality scores (weight: 15%)

  Provide your assessment in EXACT format:

  OLYMPIAD_STYLE: <yes/borderline/no>
  OLYMPIAD_STYLE_REASONING: <Does it have the characteristics of olympiad problems? Be specific.>

  PEDAGOGICAL_VALUE: <high/medium/low>
  PEDAGOGICAL_VALUE_REASONING: <What can be learned from this problem? What techniques does it teach?>

  DIFFICULTY_APPROPRIATENESS: <appropriate/too_easy/too_hard>
  DIFFICULTY_REASONING: <Why is the difficulty appropriate or not?>

  PROOF_TEACHABILITY: <yes/no>
  TEACHABILITY_REASONING: <Can this technique be generalized? Or is it too specific?>

  SUITABLE_FOR_RL_TRAINING: <yes/no>
  RL_SUITABILITY_REASONING: <Is the problem-solution pair clear enough for training?>

  IMO_READINESS_SCORE: <0-100>
  SCORE_BREAKDOWN: <Explain how you arrived at this score, referencing each component.>

  OVERALL_ASSESSMENT: <outstanding/excellent/good/acceptable/marginal/unsuitable>
  FINAL_REASONING: <综合判断：为什么这个问题适合或不适合作为 IMO 训练数据？>

  FINAL_RECOMMENDATION: <accept/review/reject>

  Output:
